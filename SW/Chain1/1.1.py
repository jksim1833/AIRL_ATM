'''
# gpt-image-1 ì‚¬ìš© ì½”ë“œ

import os
import json
import base64
import mimetypes
from pathlib import Path
from typing import List, Dict, Any
import asyncio
import argparse
import aiohttp

# ---- LangChain (OpenAI only) ----
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# =========================================
#   í”„ë¡œì íŠ¸ ë£¨íŠ¸: í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸(chain1/1.1.py) ìœ„ì¹˜
# =========================================
ROOT = Path(__file__).parent.resolve()

# ê¸°ë³¸ ORG ID (ë„¤ê°€ ì¤€ ê°’). í™˜ê²½ë³€ìˆ˜/ì‹œí¬ë¦¿ì— ë‹¤ë¥¸ ê°’ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©.
DEFAULT_ORG_ID = "org-sFasfsh6jkHg9MzL6H7pRaDh"


# =========================
#   í‚¤ ë¡œë” (tetris_secrets)
# =========================
def load_secrets() -> Dict[str, str]:
    """
    tetris_secrets / tetris_secrets.json íŒŒì¼ì„ ì°¾ì•„ OpenAI í‚¤/ORG/PROJECTë¥¼ ì½ëŠ”ë‹¤.
    ìš°ì„ ìˆœìœ„: í˜„ì¬í´ë” -> ~/Desktop -> ìƒìœ„í´ë”
    """
    names = ["tetris_secrets", "tetris_secrets.json"]
    search_dirs = [Path.cwd(), Path.home() / "Desktop", Path.cwd().parent]

    for d in search_dirs:
        for n in names:
            p = d / n
            if p.exists() and p.is_file():
                try:
                    with open(p, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    openai = data.get("openai", {}) or {}
                    return {
                        "OPENAI_API_KEY": openai.get("OPENAI_API_KEY") or "",
                        "OPENAI_ORG_ID": openai.get("OPENAI_ORG_ID")
                                         or openai.get("YOUR_ORG_ID") or "",
                        "OPENAI_PROJECT_ID": openai.get("OPENAI_PROJECT_ID") or "",
                        "_FOUND_PATH": str(p),
                    }
                except Exception as e:
                    print(f"âš ï¸ secrets íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨({p}): {e}")
    return {"OPENAI_API_KEY": "", "OPENAI_ORG_ID": "", "OPENAI_PROJECT_ID": "", "_FOUND_PATH": ""}


# =========================
#   í”„ë¡¬í”„íŠ¸ ì²´ì¸ (LCEL)
# =========================
def build_analysis_chain(llm: ChatOpenAI):
    """
    ì´ë¯¸ì§€(Data URL)ë¥¼ ì…ë ¥ë°›ì•„ gpt-image-1(í¸ì§‘)ì— ì „ë‹¬í•  'ìµœì¢… ì§€ì‹œë¬¸(ì˜ë¬¸)'ë§Œ ì‚°ì¶œ
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         # === ê°•í™”ëœ ê·œì¹™ ===
         "You are a cargo volume analysis expert. From the provided image, pick exactly ONE object "
         "whose volume is easiest to measure. You must produce a SINGLE ENGLISH sentence that will be sent "
         "to an image editing model.\n\n"
         "HARD REQUIREMENTS (must be explicitly enforced in your instruction):\n"
         "â€¢ Work on the ORIGINAL PHOTO only â€” do NOT redraw, regenerate, recompose, upscale, denoise, color-correct, or enhance the image.\n"
         "â€¢ Keep the imageâ€™s resolution, aspect ratio, perspective, lighting, and all pixels EXACTLY the same; keep metadata unchanged.\n"
         "â€¢ Overlay ONE red rectangular bounding box (#FF0000) with a 4-pixel stroke directly on the original photo around the chosen target.\n"
         "â€¢ No other edits or elements: no captions, stickers, borders, shadows, highlights, or changes outside the box.\n"
         "â€¢ The output must be the original photo PLUS only that single red box.\n"
         "â€¢ Your reply must be ONE concise English sentence only (no code blocks, no extra text)."),
        ("human", [
            {"type": "text", "text": "Analyze this image and output only the final instruction:"},
            {"type": "image_url", "image_url": {"url": "{data_url}", "detail": "high"}}
        ])
    ])
    return prompt | llm | StrOutputParser()


class LLMImageGenerationExperiment:
    def __init__(self, openai_api_key: str, openai_org_id: str = "", openai_project_id: str = ""):
        """
        LLM â†’ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì‹¤í—˜ ì´ˆê¸°í™” (OpenAI only)
        """
        self.openai_api_key = openai_api_key
        # ORG/PROJECT ìš°ì„ ìˆœìœ„: env > ì „ë‹¬ê°’ > DEFAULT
        self.openai_org_id = os.environ.get("OPENAI_ORG_ID") or openai_org_id or DEFAULT_ORG_ID
        self.openai_project_id = os.environ.get("OPENAI_PROJECT_ID") or openai_project_id or ""

        # í™˜ê²½ë³€ìˆ˜ ë°˜ì˜(ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì°¸ì¡°)
        if self.openai_api_key:
            os.environ["OPENAI_API_KEY"] = self.openai_api_key
        if self.openai_org_id:
            os.environ["OPENAI_ORG_ID"] = self.openai_org_id
        if self.openai_project_id:
            os.environ["OPENAI_PROJECT_ID"] = self.openai_project_id

        # ---------- ë¶„ì„ LLMë“¤ ----------
        self.analysis_models = {
            "gpt-4.1": ChatOpenAI(
                model="gpt-4.1",
                api_key=openai_api_key,
                max_tokens=600,
                temperature=0.1,
            ),
            "gpt-4o": ChatOpenAI(
                model="gpt-4o",
                api_key=openai_api_key,
                max_tokens=600,
                temperature=0.1,
            ),
        }

        # ---------- LLMâ†’ì´ë¯¸ì§€ìƒì„± ëª¨ë¸ ë§¤í•‘ ----------
        self.image_generators = {
            "gpt-4.1": "gpt-image-1",
            "gpt-4o": "gpt-image-1",
        }

        # ---------- ë¶„ì„ ì²´ì¸ ----------
        self._chains = {name: build_analysis_chain(llm)
                        for name, llm in self.analysis_models.items()}

    # ----------------- ìœ í‹¸ -----------------
    @staticmethod
    def _read_image_as_data_url(image_path: str) -> str:
        with open(image_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode("utf-8")
        # ê°„ë‹¨íˆ jpegë¡œ ì·¨ê¸‰ (í•„ìš”ì‹œ í™•ì¥ìì— ë§ì¶° ë°”ê¿”ë„ ë¨)
        return f"data:image/jpeg;base64,{b64}"

    def _create_output_dirs(self) -> Dict[str, Dict[str, str]]:
        base_dir = ROOT / "chain1_out" / "1.1"
        out = {}
        for name in self.analysis_models.keys():
            pdir = base_dir / "output_prompt" / name
            idir = base_dir / "output_image" / name
            pdir.mkdir(parents=True, exist_ok=True)
            idir.mkdir(parents=True, exist_ok=True)
            out[name] = {"prompt_dir": str(pdir), "image_dir": str(idir)}
        return out

    # ----------------- 1) LLM ë¶„ì„ -----------------
    async def _analyze(self, model_name: str, data_url: str,
                       outpaths: Dict[str, str]) -> Dict[str, Any]:
        try:
            chain = self._chains[model_name]
            prompt_text = await chain.ainvoke({"data_url": data_url})

            prompt_path = os.path.join(outpaths["prompt_dir"],
                                       f"{model_name}_generated_prompt.txt")
            with open(prompt_path, "w", encoding="utf-8") as f:
                f.write(prompt_text)

            return {"ok": True, "prompt": prompt_text,
                    "prompt_file": prompt_path}
        except Exception as e:
            return {"ok": False, "error": f"{model_name} analyze error: {e}"}

    # ----------------- 2) gpt-image-1 (REST /v1/images/edits) -----------------
    async def _call_images_edits(self, prompt: str, image_path: str,
                                 field_name: str = "image") -> Dict[str, Any]:
        """
        /v1/images/edits í˜¸ì¶œ; field_nameì„ 'image' ë˜ëŠ” 'image[]'ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë¶„ë¦¬
        """
        url = "https://api.openai.com/v1/images/edits"

        # í—¤ë” êµ¬ì„± (ORG/PROJECT í¬í•¨)
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "OpenAI-Organization": self.openai_org_id,
        }
        if self.openai_project_id:
            headers["OpenAI-Project"] = self.openai_project_id

        mime, _ = mimetypes.guess_type(image_path)
        if mime is None:
            mime = "image/jpeg"

        form = aiohttp.FormData()
        form.add_field("model", "gpt-image-1")
        form.add_field("prompt", prompt)
        # ğŸ”» ìš”ì²­ëŒ€ë¡œ: ê°•ì œ ì •ì‚¬ê° ë¦¬ì‚¬ì´ì¦ˆ ì œê±°
        # form.add_field("size", "1024x1024")
        form.add_field("n", "1")

        # ì´ë¯¸ì§€ íŒŒì¼ ì²¨ë¶€ (ì •í™•í•œ MIME í•„ìˆ˜)
        form.add_field(
            field_name,
            open(image_path, "rb"),
            filename=os.path.basename(image_path),
            content_type=mime
        )

        async with aiohttp.ClientSession() as sess:
            async with sess.post(url, headers=headers, data=form) as r:
                text = await r.text()
                ok = (r.status == 200)
                return {"ok": ok, "status": r.status, "text": text}

    async def _gen_with_gpt_image(self, prompt: str,
                                  outdir: str, tag: str,
                                  image_path: str) -> Dict[str, Any]:
        """
        ë¨¼ì € 'image'ë¡œ í˜¸ì¶œ â†’ ì‹¤íŒ¨ ì‹œ 'image[]'ë¡œ ì¬ì‹œë„
        """
        # 1ì°¨ ì‹œë„: image
        resp1 = await self._call_images_edits(prompt, image_path, field_name="image")
        if not resp1["ok"]:
            # 400 ë“± ì¼ë¶€ ë°°í¬ì—ì„œ ë°°ì—´ í‘œê¸° ìš”êµ¬í•˜ëŠ” ê²½ìš° ëŒ€ì‘
            should_retry_array = (resp1["status"] in (400, 422))
            if should_retry_array:
                resp2 = await self._call_images_edits(prompt, image_path, field_name="image[]")
                if not resp2["ok"]:
                    return {"ok": False, "error": f"gpt-image-1 edits HTTP {resp2['status']}: {resp2['text']}"}
                text = resp2["text"]
            else:
                return {"ok": False, "error": f"gpt-image-1 edits HTTP {resp1['status']}: {resp1['text']}"}
        else:
            text = resp1["text"]

        # JSON íŒŒì‹±
        try:
            resp_json = json.loads(text)
        except Exception:
            return {"ok": False, "error": f"invalid JSON from images/edits: {text[:300]}..."}

        try:
            b64 = resp_json["data"][0]["b64_json"]
        except Exception:
            return {"ok": False, "error": f"no b64 image in response: {resp_json}"}

        img_bytes = base64.b64decode(b64)
        Path(outdir).mkdir(parents=True, exist_ok=True)
        outpath = os.path.join(outdir, f"{tag}_gptimage1_result.png")
        with open(outpath, "wb") as f:
            f.write(img_bytes)
        return {"ok": True, "image_file": outpath}

    # ----------------- ë‹¨ì¼ ëª¨ë¸ ì²˜ë¦¬ -----------------
    async def _process_model(self, model_name: str, data_url: str,
                             outpaths: Dict[str, str], image_path: str) -> Dict[str, Any]:
        a = await self._analyze(model_name, data_url, outpaths)
        if not a.get("ok"):
            return {"model": model_name, "status": "error",
                    "error": a.get("error")}

        gen_prompt: str = a["prompt"]
        g = await self._gen_with_gpt_image(gen_prompt, outpaths["image_dir"],
                                           model_name, image_path)

        return {
            "model": model_name,
            "image_generator": "gpt-image-1",
            "analysis_status": "success",
            "prompt_file": a["prompt_file"],
            "image_generation_status": "success" if g.get("ok") else "error",
            "image_file": g.get("image_file"),
            "error": g.get("error"),
        }

    # ----------------- ì „ì²´ ì‹¤í–‰ -----------------
    async def run(self, image_path: str | None = None,
                  image_basename: str = "1") -> List[Dict[str, Any]]:
        if image_path and os.path.isfile(image_path):
            actual = image_path
            print(f"âœ… ì…ë ¥ ì´ë¯¸ì§€: {actual}")
        else:
            search_dirs = [ROOT / "chain1_image"]
            exts = [".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"]
            actual = None
            for d in search_dirs:
                base = d / image_basename
                for e in exts:
                    p = base.with_suffix(e)
                    if p.exists():
                        actual = str(p)
                        print(f"âœ… ì…ë ¥ ì´ë¯¸ì§€: {actual}")
                        break
                if actual:
                    break

        if not actual:
            hint = ROOT / "chain1_image"
            try:
                listed = ", ".join(os.listdir(hint))
            except Exception:
                listed = "(ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨)"
            return [{
                "model": "System",
                "status": "error",
                "error": f"ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --image ë¡œ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ê±°ë‚˜, "
                         f"{hint}\\{image_basename}.(jpg|png|webp..) ë¡œ ë‘ì„¸ìš”.\n"
                         f"ğŸ“ í˜„ì¬ {hint} ëª©ë¡: {listed}"
            }]

        outdirs = self._create_output_dirs()
        data_url = self._read_image_as_data_url(actual)
        tasks = [self._process_model(name, data_url, outdirs[name], actual)
                 for name in self.analysis_models.keys()]
        return await asyncio.gather(*tasks, return_exceptions=True)


# ----------------- main -----------------
async def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--image", type=str, help="ì§ì ‘ ì§€ì •í•  ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--name", type=str, help="chain1_image ì•ˆì˜ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)")
    args = parser.parse_args()

    # 1) í™˜ê²½ë³€ìˆ˜ â†’ 2) secrets íŒŒì¼
    openai_api_key = os.environ.get("OPENAI_API_KEY") or ""
    openai_org_id = os.environ.get("OPENAI_ORG_ID") or ""
    openai_project_id = os.environ.get("OPENAI_PROJECT_ID") or ""

    if not openai_api_key or not openai_org_id or not openai_project_id:
        secrets = load_secrets()
        if not openai_api_key:
            openai_api_key = secrets.get("OPENAI_API_KEY", "")
        # ORG: env > secrets > DEFAULT
        if not openai_org_id:
            openai_org_id = secrets.get("OPENAI_ORG_ID", "") or DEFAULT_ORG_ID
        # PROJECT: ì„ íƒì‚¬í•­
        if not openai_project_id:
            openai_project_id = secrets.get("OPENAI_PROJECT_ID", "")
        if secrets.get("_FOUND_PATH"):
            print(f"ğŸ”‘ secrets íŒŒì¼ ì‚¬ìš©: {secrets['_FOUND_PATH']}")

    if not openai_api_key:
        print("âŒ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í™˜ê²½ë³€ìˆ˜ì—ë„ ë°˜ì˜(í•˜ìœ„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜)
    os.environ["OPENAI_API_KEY"] = openai_api_key
    os.environ["OPENAI_ORG_ID"] = openai_org_id or DEFAULT_ORG_ID
    if openai_project_id:
        os.environ["OPENAI_PROJECT_ID"] = openai_project_id

    exp = LLMImageGenerationExperiment(
        openai_api_key=openai_api_key,
        openai_org_id=openai_org_id,
        openai_project_id=openai_project_id
    )

    print("ğŸ”¬ LLMâ†’ì´ë¯¸ì§€ ìƒì„± ì‹¤í—˜ ì‹œì‘")
    print("ğŸ¤– ë¶„ì„ LLM: gpt-4.1, gpt-4o")
    print("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±: gpt-image-1 (OpenAI Images API, edits via REST)")
    print(f"ğŸ·ï¸  Organization: {exp.openai_org_id}" + (f" | Project: {exp.openai_project_id}" if exp.openai_project_id else ""))

    results = await exp.run(image_path=args.image, image_basename=args.name or "1")

    print("\n" + "=" * 80)
    print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    print("=" * 80)
    ok = err = 0
    for r in results:
        if isinstance(r, Exception):
            print(f"âŒ ì˜ˆì™¸: {r}"); err += 1; continue
        name = r.get("model")
        print(f"\nğŸ¤– {name} -> gpt-image-1")
        if r.get("analysis_status") == "success":
            print(f"   ğŸ“ í”„ë¡¬í”„íŠ¸: {r.get('prompt_file')}")
        st = r.get("image_generation_status")
        if st == "success":
            print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {r.get('image_file')}"); ok += 1
        else:
            print(f"   âŒ ì‹¤íŒ¨: {r.get('error','unknown')}"); err += 1
    print("\nğŸ“ˆ ìš”ì•½:", f"ì„±ê³µ {ok} | ì‹¤íŒ¨ {err}")


if __name__ == "__main__":
    asyncio.run(main())
'''
import os
import json
import base64
import mimetypes
from pathlib import Path
from typing import List, Dict, Any
import asyncio
import argparse
import aiohttp

# ---- LangChain (OpenAI only) ----
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# =========================================
#   í”„ë¡œì íŠ¸ ë£¨íŠ¸: í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸(chain1/1.1.py) ìœ„ì¹˜
# =========================================
ROOT = Path(__file__).parent.resolve()

# ê¸°ë³¸ ORG ID (ë„¤ê°€ ì¤€ ê°’). í™˜ê²½ë³€ìˆ˜/ì‹œí¬ë¦¿ì— ë‹¤ë¥¸ ê°’ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©.
DEFAULT_ORG_ID = "org-sFasfsh6jkHg9MzL6H7pRaDh"


# =========================
#   í‚¤ ë¡œë” (tetris_secrets)
# =========================
def load_secrets() -> Dict[str, str]:
    """
    tetris_secrets / tetris_secrets.json íŒŒì¼ì„ ì°¾ì•„ OpenAI í‚¤/ORG/PROJECTë¥¼ ì½ëŠ”ë‹¤.
    ìš°ì„ ìˆœìœ„: ìƒìœ„í´ë”(SW) -> í˜„ì¬í´ë” -> ~/Desktop
    """
    names = ["tetris_secrets", "tetris_secrets.json"]
    search_dirs = [
        Path.cwd().parent,  # SW í´ë” (chain1ì˜ ìƒìœ„)
        Path.cwd(),         # í˜„ì¬ í´ë” (chain1)
        Path.home() / "Desktop"
    ]

    print("ğŸ” tetris_secrets íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
    for d in search_dirs:
        print(f"   ğŸ“ ê²€ìƒ‰ í´ë”: {d}")
        for n in names:
            p = d / n
            print(f"      ğŸ” í™•ì¸: {p}")
            if p.exists() and p.is_file():
                print(f"      âœ… ë°œê²¬: {p}")
                try:
                    with open(p, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    openai = data.get("openai", {}) or {}
                    print(f"      ğŸ“‹ í‚¤ í™•ì¸: OPENAI_API_KEY={'ìˆìŒ' if openai.get('OPENAI_API_KEY') else 'ì—†ìŒ'}")
                    print(f"      ğŸ“‹ í‚¤ í™•ì¸: YOUR_ORG_ID={'ìˆìŒ' if openai.get('YOUR_ORG_ID') else 'ì—†ìŒ'}")
                    return {
                        "OPENAI_API_KEY": openai.get("OPENAI_API_KEY") or "",
                        "OPENAI_ORG_ID": openai.get("YOUR_ORG_ID") or openai.get("OPENAI_ORG_ID") or "",
                        "OPENAI_PROJECT_ID": openai.get("OPENAI_PROJECT_ID") or "",
                        "_FOUND_PATH": str(p),
                    }
                except Exception as e:
                    print(f"âš ï¸ secrets íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨({p}): {e}")
            else:
                print(f"      âŒ ì—†ìŒ: {p}")
    
    print("âŒ tetris_secrets.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return {"OPENAI_API_KEY": "", "OPENAI_ORG_ID": "", "OPENAI_PROJECT_ID": "", "_FOUND_PATH": ""}


# =========================
#   í”„ë¡¬í”„íŠ¸ ì²´ì¸ (LCEL)
# =========================
def build_analysis_chain(llm: ChatOpenAI):
    """
    ì´ë¯¸ì§€(Data URL)ë¥¼ ì…ë ¥ë°›ì•„ gpt-image-1(í¸ì§‘)ì— ì „ë‹¬í•  'ìµœì¢… ì§€ì‹œë¬¸(ì˜ë¬¸)'ë§Œ ì‚°ì¶œ
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         # === ë§¤ìš° ê°•í™”ëœ ê·œì¹™ ===
         "You are a cargo volume analysis expert. From the provided image, pick exactly ONE object "
         "whose volume is easiest to measure. You must produce a SINGLE ENGLISH sentence that will be sent "
         "to an image editing model.\n\n"
         "CRITICAL REQUIREMENTS (absolutely no exceptions):\n"
         "â€¢ PRESERVE EXACT ORIGINAL IMAGE: Keep every single pixel, dimension, resolution, and aspect ratio identical to the input.\n"
         "â€¢ NO RESIZING: Do not change image width, height, or dimensions in any way. Keep original size exactly.\n"
         "â€¢ NO CROPPING: Do not crop, trim, or cut any part of the original image.\n"
         "â€¢ NO ENHANCEMENT: Do not upscale, denoise, color-correct, sharpen, blur, or modify any visual properties.\n"
         "â€¢ ONLY ADD RED BOX: The ONLY change allowed is adding one red rectangular outline (#FF0000, 4px stroke) around the chosen object.\n"
         "â€¢ PRESERVE ASPECT RATIO: Maintain the exact original width-to-height ratio without any modification.\n"
         "â€¢ NO BACKGROUND CHANGES: Keep the original background, lighting, shadows, and all environmental elements unchanged.\n"
         "â€¢ PIXEL-PERFECT PRESERVATION: Every pixel outside the red box must remain exactly as in the original.\n"
         "â€¢ Your instruction must explicitly state 'preserve original dimensions and aspect ratio exactly'.\n"
         "â€¢ Your reply must be ONE concise English sentence only."),
        ("human", [
            {"type": "text", "text": "Analyze this image and output only the final instruction:"},
            {"type": "image_url", "image_url": {"url": "{data_url}", "detail": "high"}}
        ])
    ])
    return prompt | llm | StrOutputParser()


class LLMImageGenerationExperiment:
    def __init__(self, openai_api_key: str, openai_org_id: str = "", openai_project_id: str = ""):
        """
        LLM â†’ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì‹¤í—˜ ì´ˆê¸°í™” (OpenAI only)
        """
        self.openai_api_key = openai_api_key
        # ORG/PROJECT ìš°ì„ ìˆœìœ„: env > ì „ë‹¬ê°’ > DEFAULT
        self.openai_org_id = os.environ.get("OPENAI_ORG_ID") or openai_org_id or DEFAULT_ORG_ID
        self.openai_project_id = os.environ.get("OPENAI_PROJECT_ID") or openai_project_id or ""

        # í™˜ê²½ë³€ìˆ˜ ë°˜ì˜(ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì°¸ì¡°)
        if self.openai_api_key:
            os.environ["OPENAI_API_KEY"] = self.openai_api_key
        if self.openai_org_id:
            os.environ["OPENAI_ORG_ID"] = self.openai_org_id
        if self.openai_project_id:
            os.environ["OPENAI_PROJECT_ID"] = self.openai_project_id

        # ---------- ë¶„ì„ LLMë“¤ ----------
        self.analysis_models = {
            "gpt-4.1": ChatOpenAI(
                model="gpt-4.1",
                api_key=openai_api_key,
                max_tokens=600,
                temperature=0.1,
            ),
            "gpt-4o": ChatOpenAI(
                model="gpt-4o",
                api_key=openai_api_key,
                max_tokens=600,
                temperature=0.1,
            ),
        }

        # ---------- LLMâ†’ì´ë¯¸ì§€ìƒì„± ëª¨ë¸ ë§¤í•‘ ----------
        self.image_generators = {
            "gpt-4.1": "gpt-image-1",
            "gpt-4o": "gpt-image-1",
        }

        # ---------- ë¶„ì„ ì²´ì¸ ----------
        self._chains = {name: build_analysis_chain(llm)
                        for name, llm in self.analysis_models.items()}

    # ----------------- ìœ í‹¸ -----------------
    @staticmethod
    def _read_image_as_data_url(image_path: str) -> str:
        with open(image_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode("utf-8")
        # MIME íƒ€ì…ì„ ì •í™•íˆ ê°ì§€
        mime, _ = mimetypes.guess_type(image_path)
        if mime is None:
            mime = "image/jpeg"
        return f"data:{mime};base64,{b64}"

    def _create_output_dirs(self) -> Dict[str, Dict[str, str]]:
        base_dir = ROOT / "chain1_out" / "1.1"
        out = {}
        for name in self.analysis_models.keys():
            pdir = base_dir / "output_prompt" / name
            idir = base_dir / "output_image" / name
            pdir.mkdir(parents=True, exist_ok=True)
            idir.mkdir(parents=True, exist_ok=True)
            out[name] = {"prompt_dir": str(pdir), "image_dir": str(idir)}
        return out

    # ----------------- 1) LLM ë¶„ì„ -----------------
    async def _analyze(self, model_name: str, data_url: str,
                       outpaths: Dict[str, str]) -> Dict[str, Any]:
        try:
            chain = self._chains[model_name]
            prompt_text = await chain.ainvoke({"data_url": data_url})

            prompt_path = os.path.join(outpaths["prompt_dir"],
                                       f"{model_name}_generated_prompt.txt")
            with open(prompt_path, "w", encoding="utf-8") as f:
                f.write(prompt_text)

            return {"ok": True, "prompt": prompt_text,
                    "prompt_file": prompt_path}
        except Exception as e:
            return {"ok": False, "error": f"{model_name} analyze error: {e}"}

    # ----------------- 2) gpt-image-1 (REST /v1/images/edits) -----------------
    async def _call_images_edits(self, prompt: str, image_path: str,
                                 field_name: str = "image") -> Dict[str, Any]:
        """
        /v1/images/edits í˜¸ì¶œ; ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì™€ ì¢…íš¡ë¹„ë¥¼ ì™„ì „íˆ ìœ ì§€
        """
        url = "https://api.openai.com/v1/images/edits"

        # í—¤ë” êµ¬ì„± (ORG/PROJECT í¬í•¨)
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "OpenAI-Organization": self.openai_org_id,
        }
        if self.openai_project_id:
            headers["OpenAI-Project"] = self.openai_project_id

        mime, _ = mimetypes.guess_type(image_path)
        if mime is None:
            mime = "image/jpeg"

        # í¬ê¸° ë³´ì¡´ì„ ê°•ì¡°í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        enhanced_prompt = f"{prompt} Preserve original dimensions and aspect ratio exactly, do not resize or crop the image."

        form = aiohttp.FormData()
        form.add_field("model", "gpt-image-1")
        form.add_field("prompt", enhanced_prompt)
        # ğŸš¨ ì¤‘ìš”: size íŒŒë¼ë¯¸í„°ë¥¼ ì™„ì „íˆ ì œê±°í•˜ì—¬ ì›ë³¸ í¬ê¸° ìœ ì§€
        # ì •ì‚¬ê°í˜• ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ ë°©ì§€
        form.add_field("n", "1")

        # ì´ë¯¸ì§€ íŒŒì¼ ì²¨ë¶€ (ì •í™•í•œ MIME í•„ìˆ˜)
        with open(image_path, "rb") as img_file:
            form.add_field(
                field_name,
                img_file,
                filename=os.path.basename(image_path),
                content_type=mime
            )

            async with aiohttp.ClientSession() as sess:
                async with sess.post(url, headers=headers, data=form) as r:
                    text = await r.text()
                    ok = (r.status == 200)
                    return {"ok": ok, "status": r.status, "text": text}

    async def _gen_with_gpt_image(self, prompt: str,
                                  outdir: str, tag: str,
                                  image_path: str) -> Dict[str, Any]:
        """
        ë¨¼ì € 'image'ë¡œ í˜¸ì¶œ â†’ ì‹¤íŒ¨ ì‹œ 'image[]'ë¡œ ì¬ì‹œë„
        """
        # 1ì°¨ ì‹œë„: image
        resp1 = await self._call_images_edits(prompt, image_path, field_name="image")
        if not resp1["ok"]:
            # 400 ë“± ì¼ë¶€ ë°°í¬ì—ì„œ ë°°ì—´ í‘œê¸° ìš”êµ¬í•˜ëŠ” ê²½ìš° ëŒ€ì‘
            should_retry_array = (resp1["status"] in (400, 422))
            if should_retry_array:
                resp2 = await self._call_images_edits(prompt, image_path, field_name="image[]")
                if not resp2["ok"]:
                    return {"ok": False, "error": f"gpt-image-1 edits HTTP {resp2['status']}: {resp2['text']}"}
                text = resp2["text"]
            else:
                return {"ok": False, "error": f"gpt-image-1 edits HTTP {resp1['status']}: {resp1['text']}"}
        else:
            text = resp1["text"]

        # JSON íŒŒì‹±
        try:
            resp_json = json.loads(text)
        except Exception:
            return {"ok": False, "error": f"invalid JSON from images/edits: {text[:300]}..."}

        try:
            b64 = resp_json["data"][0]["b64_json"]
        except Exception:
            return {"ok": False, "error": f"no b64 image in response: {resp_json}"}

        img_bytes = base64.b64decode(b64)
        Path(outdir).mkdir(parents=True, exist_ok=True)
        outpath = os.path.join(outdir, f"{tag}_gptimage1_result.png")
        with open(outpath, "wb") as f:
            f.write(img_bytes)
        return {"ok": True, "image_file": outpath}

    # ----------------- ë‹¨ì¼ ëª¨ë¸ ì²˜ë¦¬ -----------------
    async def _process_model(self, model_name: str, data_url: str,
                             outpaths: Dict[str, str], image_path: str) -> Dict[str, Any]:
        a = await self._analyze(model_name, data_url, outpaths)
        if not a.get("ok"):
            return {"model": model_name, "status": "error",
                    "error": a.get("error")}

        gen_prompt: str = a["prompt"]
        g = await self._gen_with_gpt_image(gen_prompt, outpaths["image_dir"],
                                           model_name, image_path)

        return {
            "model": model_name,
            "image_generator": "gpt-image-1",
            "analysis_status": "success",
            "prompt_file": a["prompt_file"],
            "image_generation_status": "success" if g.get("ok") else "error",
            "image_file": g.get("image_file"),
            "error": g.get("error"),
        }

    # ----------------- ì „ì²´ ì‹¤í–‰ -----------------
    async def run(self, image_path: str | None = None,
                  image_basename: str = "1") -> List[Dict[str, Any]]:
        if image_path and os.path.isfile(image_path):
            actual = image_path
            print(f"âœ… ì…ë ¥ ì´ë¯¸ì§€: {actual}")
        else:
            search_dirs = [ROOT / "chain1_image"]
            exts = [".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"]
            actual = None
            for d in search_dirs:
                base = d / image_basename
                for e in exts:
                    p = base.with_suffix(e)
                    if p.exists():
                        actual = str(p)
                        print(f"âœ… ì…ë ¥ ì´ë¯¸ì§€: {actual}")
                        break
                if actual:
                    break

        if not actual:
            hint = ROOT / "chain1_image"
            try:
                listed = ", ".join(os.listdir(hint))
            except Exception:
                listed = "(ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨)"
            return [{
                "model": "System",
                "status": "error",
                "error": f"ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --image ë¡œ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ê±°ë‚˜, "
                         f"{hint}\\{image_basename}.(jpg|png|webp..) ë¡œ ë‘ì„¸ìš”.\n"
                         f"ğŸ“ í˜„ì¬ {hint} ëª©ë¡: {listed}"
            }]

        outdirs = self._create_output_dirs()
        data_url = self._read_image_as_data_url(actual)
        tasks = [self._process_model(name, data_url, outdirs[name], actual)
                 for name in self.analysis_models.keys()]
        return await asyncio.gather(*tasks, return_exceptions=True)


# ----------------- main -----------------
async def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--image", type=str, help="ì§ì ‘ ì§€ì •í•  ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--name", type=str, help="chain1_image ì•ˆì˜ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)")
    args = parser.parse_args()

    # 1) í™˜ê²½ë³€ìˆ˜ â†’ 2) secrets íŒŒì¼
    openai_api_key = os.environ.get("OPENAI_API_KEY") or ""
    openai_org_id = os.environ.get("OPENAI_ORG_ID") or ""
    openai_project_id = os.environ.get("OPENAI_PROJECT_ID") or ""

    if not openai_api_key or not openai_org_id or not openai_project_id:
        secrets = load_secrets()
        if not openai_api_key:
            openai_api_key = secrets.get("OPENAI_API_KEY", "")
        # ORG: env > secrets > DEFAULT
        if not openai_org_id:
            openai_org_id = secrets.get("OPENAI_ORG_ID", "") or DEFAULT_ORG_ID
        # PROJECT: ì„ íƒì‚¬í•­
        if not openai_project_id:
            openai_project_id = secrets.get("OPENAI_PROJECT_ID", "")
        if secrets.get("_FOUND_PATH"):
            print(f"ğŸ”‘ secrets íŒŒì¼ ì‚¬ìš©: {secrets['_FOUND_PATH']}")

    if not openai_api_key:
        print("âŒ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í™˜ê²½ë³€ìˆ˜ì—ë„ ë°˜ì˜(í•˜ìœ„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜)
    os.environ["OPENAI_API_KEY"] = openai_api_key
    os.environ["OPENAI_ORG_ID"] = openai_org_id or DEFAULT_ORG_ID
    if openai_project_id:
        os.environ["OPENAI_PROJECT_ID"] = openai_project_id

    exp = LLMImageGenerationExperiment(
        openai_api_key=openai_api_key,
        openai_org_id=openai_org_id,
        openai_project_id=openai_project_id
    )

    print("ğŸ”¬ LLMâ†’ì´ë¯¸ì§€ ìƒì„± ì‹¤í—˜ ì‹œì‘")
    print("ğŸ¤– ë¶„ì„ LLM: gpt-4.1, gpt-4o")
    print("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±: gpt-image-1 (OpenAI Images API, edits via REST)")
    print("ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì™€ ì¢…íš¡ë¹„ ì™„ì „ ìœ ì§€ (ì •ì‚¬ê°í˜• ê°•ì œ ì—†ìŒ)")
    print(f"ğŸ·ï¸  Organization: {exp.openai_org_id}" + (f" | Project: {exp.openai_project_id}" if exp.openai_project_id else ""))

    results = await exp.run(image_path=args.image, image_basename=args.name or "1")

    print("\n" + "=" * 80)
    print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    print("=" * 80)
    ok = err = 0
    for r in results:
        if isinstance(r, Exception):
            print(f"âŒ ì˜ˆì™¸: {r}"); err += 1; continue
        name = r.get("model")
        print(f"\nğŸ¤– {name} -> gpt-image-1")
        if r.get("analysis_status") == "success":
            print(f"   ğŸ“ í”„ë¡¬í”„íŠ¸: {r.get('prompt_file')}")
        st = r.get("image_generation_status")
        if st == "success":
            print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {r.get('image_file')}"); ok += 1
        else:
            print(f"   âŒ ì‹¤íŒ¨: {r.get('error','unknown')}"); err += 1
    print("\nğŸ“ˆ ìš”ì•½:", f"ì„±ê³µ {ok} | ì‹¤íŒ¨ {err}")


if __name__ == "__main__":
    asyncio.run(main())